I will be uploading zip files , so give me a very secure and simple python lambda function which generates s3 presigned url

Here's a secure Lambda function for generating S3 presigned URLs specifically for ZIP file uploads [1][2][3]:

```python
import boto3
import json
import uuid
import re
from datetime import datetime

def lambda_handler(event, context):
    """
    Secure Lambda function to generate S3 presigned URLs for ZIP uploads
    """
    
    # Initialize S3 client
    s3_client = boto3.client('s3', region_name='us-east-1')
    
    # Configuration
    BUCKET_NAME = 'your-secure-bucket-name'
    MAX_FILE_SIZE = 100 * 1024 * 1024  # 100MB max
    URL_EXPIRATION = 900  # 15 minutes (short-lived for security)
    ALLOWED_CONTENT_TYPE = 'application/zip'
    
    try:
        # Parse request
        body = json.loads(event.get('body', '{}'))
        original_filename = body.get('filename', '')
        file_size = body.get('file_size', 0)
        
        # 1. Validate filename exists
        if not original_filename:
            return error_response(400, 'Filename is required')
        
        # 2. Validate file extension
        if not original_filename.lower().endswith('.zip'):
            return error_response(400, 'Only ZIP files are allowed')
        
        # 3. Validate file size
        if file_size <= 0 or file_size > MAX_FILE_SIZE:
            return error_response(400, f'File size must be between 1 byte and {MAX_FILE_SIZE} bytes')
        
        # 4. Sanitize filename - use UUID to prevent path traversal
        safe_filename = sanitize_filename(original_filename)
        unique_key = f"uploads/{datetime.utcnow().strftime('%Y/%m/%d')}/{uuid.uuid4()}-{safe_filename}"
        
        # 5. Generate presigned URL with security conditions
        presigned_url = s3_client.generate_presigned_url(
            ClientMethod='put_object',
            Params={
                'Bucket': BUCKET_NAME,
                'Key': unique_key,
                'ContentType': ALLOWED_CONTENT_TYPE,
                'ContentLength': file_size,
                'ServerSideEncryption': 'AES256',  # Enforce encryption
                'Metadata': {
                    'original-filename': safe_filename,
                    'upload-timestamp': str(int(datetime.utcnow().timestamp()))
                }
            },
            ExpiresIn=URL_EXPIRATION,
            HttpMethod='PUT'
        )
        
        # 6. Return response
        return {
            'statusCode': 200,
            'headers': {
                'Content-Type': 'application/json',
                'Access-Control-Allow-Origin': '*',
                'Access-Control-Allow-Headers': 'Content-Type',
                'Access-Control-Allow-Methods': 'POST'
            },
            'body': json.dumps({
                'upload_url': presigned_url,
                'file_key': unique_key,
                'expires_in_seconds': URL_EXPIRATION,
                'required_headers': {
                    'Content-Type': ALLOWED_CONTENT_TYPE,
                    'Content-Length': str(file_size)
                },
                'instructions': 'Use PUT method with specified headers'
            })
        }
        
    except json.JSONDecodeError:
        return error_response(400, 'Invalid JSON in request body')
    except Exception as e:
        print(f"Error: {str(e)}")
        return error_response(500, 'Internal server error')


def sanitize_filename(filename):
    """
    Sanitize filename to prevent path traversal and other attacks
    """
    # Remove path separators and special characters
    filename = filename.replace('\\', '').replace('/', '')
    filename = re.sub(r'[^\w\s.-]', '', filename)
    
    # Limit length
    name_parts = filename.rsplit('.', 1)
    if len(name_parts[0]) > 100:
        name_parts[0] = name_parts[0][:100]
    
    return '.'.join(name_parts) if len(name_parts) == 2 else filename[:100]


def error_response(status_code, message):
    """
    Generate error response
    """
    return {
        'statusCode': status_code,
        'headers': {
            'Content-Type': 'application/json',
            'Access-Control-Allow-Origin': '*'
        },
        'body': json.dumps({'error': message})
    }
```

## Security Features Implemented

This function includes multiple security layers [1][4][3]:

1. **UUID-based filenames**: Prevents path traversal attacks by using UUIDs instead of user-provided filenames [1]
2. **Content-Type enforcement**: Restricts uploads to `application/zip` only [4][5]
3. **File size validation**: Enforces max 100MB limit using `ContentLength` parameter [1][3]
4. **Short expiration**: 15-minute URL lifetime minimizes exposure if URL is leaked [1][3]
5. **Server-side encryption**: Enforces AES256 encryption for all uploads [2]
6. **Filename sanitization**: Removes dangerous characters and path separators [1]
7. **Date-based organization**: Stores files in date-partitioned folders for easier management [2]

## Required IAM Permissions

Add to your Lambda execution role [2]:

```json
{
  "Version": "2012-10-17",
  "Statement": [{
    "Effect": "Allow",
    "Action": [
      "s3:PutObject",
      "s3:PutObjectAcl"
    ],
    "Resource": "arn:aws:s3:::your-secure-bucket-name/*"
  }]
}
```

## Client Upload Example

```python
import requests

# Get presigned URL
response = requests.post('https://your-api-gateway-url/generate-upload-url', 
    json={
        'filename': 'mydata.zip',
        'file_size': 15728640  # 15MB in bytes
    }
)

data = response.json()

# Upload file
with open('mydata.zip', 'rb') as f:
    upload_response = requests.put(
        data['upload_url'],
        data=f,
        headers={
            'Content-Type': 'application/zip',
            'Content-Length': str(15728640)
        }
    )

print(f"Upload status: {upload_response.status_code}")
```

## Post-Upload Validation

Add an S3 event trigger to validate uploaded files [4]:

```python
# Separate Lambda triggered by S3 event
def validate_upload(event, context):
    s3_client = boto3.client('s3')
    
    for record in event['Records']:
        bucket = record['s3']['bucket']['name']
        key = record['s3']['object']['key']
        
        # Get object metadata
        obj = s3_client.head_object(Bucket=bucket, Key=key)
        
        # Verify content type
        if obj['ContentType'] != 'application/zip':
            s3_client.delete_object(Bucket=bucket, Key=key)
            print(f"Deleted invalid file: {key}")
```

This approach ensures only valid ZIP files are uploaded with minimal exposure window [4][3].

Citations:
[1] Securing your Amazon AWS S3 presigned URLs, tips and tricks https://insecurity.blog/2021/03/06/securing-amazon-s3-presigned-urls/
[2] Presigned URLs - Boto3 1.42.5 documentation https://boto3.amazonaws.com/v1/documentation/api/latest/guide/s3-presigned-urls.html
[3] Securing Amazon S3 presigned URLs for serverless ... https://aws.amazon.com/blogs/compute/securing-amazon-s3-presigned-urls-for-serverless-applications/
[4] content-type validation during file uploads to an AWS S3 ... https://devsecopssourav.hashnode.dev/content-type-validation-during-file-uploads-to-an-aws-s3-bucket
[5] S3 Pre-signed POST validate file type? https://stackoverflow.com/questions/39226673/s3-pre-signed-post-validate-file-type
[6] Download and upload objects with presigned URLs https://docs.aws.amazon.com/AmazonS3/latest/userguide/using-presigned-url.html
[7] Sharing objects with presigned URLs - AWS Documentation https://docs.aws.amazon.com/AmazonS3/latest/userguide/ShareObjectPreSignedURL.html
[8] How secure are presigned URLs in AWS S3? https://stackoverflow.com/questions/17185490/how-secure-are-presigned-urls-in-aws-s3
[9] AWS S3 Presigned URL Upload Tutorial in Python https://www.youtube.com/watch?v=1D9ggTJ9Ejc
[10] Content Type not enforced in s3 pre-signed POST https://stackoverflow.com/questions/51935747/content-type-not-enforced-in-s3-pre-signed-post
